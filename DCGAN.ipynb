{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Deep Convolutional Generative Adversarial Network\n",
    "A Generative Adversarial Network (GAN) is capable of finding the probability distribution of a dataset and sample from it to produce new images very close to the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data from tf examples\n",
    "\n",
    "image_height = 28\n",
    "image_width = 28\n",
    "\n",
    "color_channels = 1\n",
    "\n",
    "model_name = \"mnist\"\n",
    "\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "\n",
    "train_data = mnist.train.images\n",
    "train_data = np.reshape(train_data, (-1, image_height, image_width, color_channels))\n",
    " \n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the discriminator network\n",
    "The discriminator network takes images as an input and is trained to find the probability that the given image is fake, or created by the generator, or real, pulled out of the dataset. It uses convolutional layers, leaky relu activations and batch normalization to increase training speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "def create_discriminator(image, reuse=False):\n",
    "\n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuse) as scope:\n",
    "        w1 = tf.get_variable(\"conv1weights\", \n",
    "                             shape=[5, 5, color_channels, 16], \n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b1 = tf.get_variable(\"conv1biases\", \n",
    "                             shape=[16],  \n",
    "                             initializer=tf.constant_initializer(0))\n",
    "        conv1 = tf.nn.conv2d(image, w1, [1, 1, 1, 1], \"SAME\") + b1\n",
    "        norm_conv1 = tf.nn.leaky_relu(tf.contrib.layers.batch_norm(conv1, epsilon=1e-5))\n",
    "        pool1 = tf.layers.max_pooling2d(norm_conv1, [2, 2], [2, 2], \"SAME\")\n",
    "        \n",
    "        w2 = tf.get_variable(\"conv2weights\", \n",
    "                             shape=[5, 5, 16, 32], \n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b2 = tf.get_variable(\"conv2biases\", \n",
    "                             shape=[32], \n",
    "                             initializer=tf.constant_initializer(0))\n",
    "        conv2 = tf.nn.conv2d(pool1, w2, [1, 1, 1, 1], \"SAME\") + b2\n",
    "        norm_conv2 = tf.nn.leaky_relu(tf.contrib.layers.batch_norm(conv2, epsilon=1e-5))\n",
    "        pool2 = tf.layers.max_pooling2d(norm_conv2, [2, 2], [2, 2], \"SAME\")\n",
    "        \n",
    "        w3 = tf.get_variable(\"conv3weights\", \n",
    "                             shape=[5, 5, 32, 64], \n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b3 = tf.get_variable(\"conv3biases\", \n",
    "                             shape=[64], \n",
    "                             initializer=tf.constant_initializer(0))\n",
    "        conv3 = tf.nn.conv2d(pool2, w3, [1, 1, 1, 1], \"SAME\") + b3\n",
    "        norm_conv3 = tf.nn.leaky_relu(tf.contrib.layers.batch_norm(conv3, epsilon=1e-5))\n",
    "        pool3 = tf.layers.max_pooling2d(norm_conv3, [2, 2], [2, 2], \"SAME\")\n",
    "        flatten = tf.layers.flatten(pool3)\n",
    "        \n",
    "        w5 = tf.get_variable(\"dense1weights\", \n",
    "                             shape=[1024, 1], \n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b5 = tf.get_variable(\"dense1biases\", \n",
    "                             shape=[1, 1], \n",
    "                             initializer=tf.constant_initializer(0))\n",
    "        output = tf.sigmoid(tf.matmul(flatten, w5) + b5)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the generator network\n",
    "The generator network takes in a sample 'z' from the normal distribution as a 100-D vector and applies transpose convolutions with relu and, once again, batch normalization to essentially transform the normal distribution into the distribution of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "def create_generator(z, reuse=False):\n",
    "    with tf.variable_scope(\"generator\", reuse=reuse) as scope:\n",
    "        batch_size = tf.shape(z)[0]\n",
    "        \n",
    "        w1 = tf.get_variable(\"dense1weights\", \n",
    "                             shape=[noise_length, 4096], \n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b1 = tf.get_variable(\"dense1biases\", \n",
    "                             shape=[1, 4096], \n",
    "                             initializer=tf.constant_initializer(0))\n",
    "        dense1 = tf.matmul(z, w1) + b1\n",
    "        norm_dense1 = tf.nn.relu(tf.contrib.layers.batch_norm(dense1))\n",
    "        \n",
    "        \n",
    "        conv_input = tf.reshape(norm_dense1, shape=[-1, 4, 4, 256])\n",
    "        \n",
    "        w2 = tf.get_variable(\"conv1weights\", \n",
    "                             shape=[5, 5, 64, 256], \n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b2 = tf.get_variable(\"conv1biases\",\n",
    "                             shape=[64],\n",
    "                             initializer=tf.constant_initializer(0))\n",
    "        conv1 = tf.nn.conv2d_transpose(conv_input, w2, [batch_size, 8, 8, 64], [1, 2, 2, 1]) + b2\n",
    "        norm_conv1 = tf.nn.relu(tf.contrib.layers.batch_norm(conv1))\n",
    "        \n",
    "        w3 = tf.get_variable(\"conv2weights\", \n",
    "                             shape=[5, 5, 32, 64], \n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b3 = tf.get_variable(\"conv2biases\",\n",
    "                             shape=[32],\n",
    "                             initializer=tf.constant_initializer(0))\n",
    "        conv2 = tf.nn.conv2d_transpose(norm_conv1, w3, [batch_size, 16, 16, 32], [1, 2, 2, 1]) + b3\n",
    "        norm_conv2 = tf.nn.relu(tf.contrib.layers.batch_norm(conv2))\n",
    "        \n",
    "        w4 = tf.get_variable(\"conv3weights\", \n",
    "                             shape=[5, 5, 16, 32], \n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b4 = tf.get_variable(\"conv3biases\",\n",
    "                             shape=[16],\n",
    "                             initializer=tf.constant_initializer(0))\n",
    "        conv3 = tf.nn.conv2d_transpose(norm_conv2, w4, [batch_size, 32, 32, 16], [1, 2, 2, 1]) + b4\n",
    "        norm_conv3 = tf.nn.relu(tf.contrib.layers.batch_norm(conv3))\n",
    "        \n",
    "        w5 = tf.get_variable(\"conv4weights\", \n",
    "                             shape=[32, 32, color_channels, 16], \n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b5 = tf.get_variable(\"conv4biases\",\n",
    "                             shape=[color_channels],\n",
    "                             initializer=tf.constant_initializer(0))\n",
    "        conv4 = tf.nn.conv2d_transpose(norm_conv3, w5, [batch_size, 32, 32, color_channels], [1, 1, 1, 1]) + b5\n",
    "        output = tf.sigmoid(conv4)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial loss\n",
    "The discriminator is given both real images from the MNIST dataset and fake images created by the generator. The discriminator is optimized to distinguish between real and fake, while the generator is trying to maximize the loss of the discriminator. This creates an adversary, making convergence extremely difficult, however allowing the generator to get closer and closer to finding the probability distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "color_channels = 1\n",
    "noise_length = 100\n",
    "\n",
    "# Placeholders\n",
    "x_images = tf.placeholder(dtype=tf.float32, shape=[None, img_height, img_width, color_channels])\n",
    "noise = tf.placeholder(dtype=tf.float32, shape=[None, noise_length])\n",
    "\n",
    "# Minimax\n",
    "real = create_discriminator(x_images)\n",
    "fake = create_discriminator(create_generator(noise), reuse=True)\n",
    "\n",
    "gen_loss = -tf.reduce_mean(tf.log(fake))\n",
    "disc_loss = -tf.reduce_mean(tf.log(real) + tf.log(1 - fake))\n",
    "\n",
    "gen_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"generator\")\n",
    "disc_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"discriminator\")\n",
    "\n",
    "train_gen = tf.train.AdamOptimizer(learning_rate=0.0002, beta1=0.5).minimize(gen_loss, var_list=gen_vars)\n",
    "train_disc = tf.train.AdamOptimizer(learning_rate=0.0002, beta1=0.5).minimize(disc_loss, var_list=disc_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "load_checkpoint = True\n",
    "path = \"GAN checkpoints/\"\n",
    "saver = tf.train.Saver(max_to_keep=8)\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 50000\n",
    "display_step = 10\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "if load_checkpoint:\n",
    "    checkpoint = tf.train.get_checkpoint_state(path)\n",
    "    saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "current_batch_index = 0\n",
    "\n",
    "test_gen = create_generator(np.random.uniform(-1.0, 1.0, size=[16, noise_length]).astype(np.float32), reuse=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batch_xs = np.array(train_data[current_batch_index:current_batch_index + batch_size])\n",
    "    batch_xs = np.lib.pad(batch_xs, ((0,0),(2,2),(2,2),(0,0)),'constant')\n",
    "    \n",
    "    if current_batch_index + batch_size >= len(train_data):\n",
    "        current_batch_index = 0\n",
    "    else:\n",
    "        current_batch_index += batch_size\n",
    "        \n",
    "    zs = np.random.uniform(-1.0, 1.0, size=[batch_size, noise_length]).astype(np.float32)\n",
    "        \n",
    "    if epoch % display_step == 0:\n",
    "        a = np.array(sess.run(test_gen))\n",
    "        save_sample(a, \"Generated/\" + str(epoch) + \".bmp\", [4, 4])\n",
    "        saver.save(sess, path + model_name, epoch)\n",
    "        \n",
    "    sess.run(train_disc, feed_dict={x_images: batch_xs, noise: zs})\n",
    "    sess.run(train_gen, feed_dict={noise: zs})\n",
    "    sess.run(train_gen, feed_dict={noise: zs})\n",
    "    \n",
    "    print(\"Epoch\", \n",
    "          epoch, \n",
    "          \"Generator Loss\", \n",
    "          sess.run(gen_loss, \n",
    "                   feed_dict={noise: zs}), \n",
    "          \"Discriminator Loss\", \n",
    "          sess.run(disc_loss, \n",
    "                   feed_dict={x_images: batch_xs, noise: zs}))\n",
    "    \n",
    "saver.save(sess, path + model_name, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image saving function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving image samples\n",
    "def save_sample(images_array, filename, shape):\n",
    "    \n",
    "    img_width = images_array.shape[1]\n",
    "    img_height = images_array.shape[2]\n",
    "    \n",
    "    final_width = img_width * shape[0]\n",
    "    final_height = img_width * shape[1]\n",
    "    \n",
    "    final_arr = np.zeros((final_width, final_height))\n",
    "    \n",
    "    for i in range(len(images_array)):\n",
    "        x = int(i % shape[0]) * img_width\n",
    "        y = int(i / shape[0]) * img_height\n",
    "        \n",
    "        final_arr[x:x + img_width, y:y + img_height] = images_array[i].reshape(img_height, img_width)\n",
    "        \n",
    "    final_img = Image.fromarray((final_arr * 255).astype(np.uint8), mode=\"L\")\n",
    "    final_img.save(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
